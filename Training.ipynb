{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import print_function \n",
    "\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = \"./training_data\"\n",
    "IMAGE_DIR = \"IMG\"\n",
    "\n",
    "CORRECTION = 0.2\n",
    "\n",
    "\n",
    "\n",
    "def process_images(image_files, \n",
    "                   local_dirname, \n",
    "                   #normalizer = keras_normalizer,\n",
    "                   batch_size = 512):\n",
    "    '''Crops Images to remove hood and scenery above the horizon'''\n",
    "    print (\"Processing\", len(image_files), \"images\")\n",
    "    \n",
    "    image_files = [os.path.join(DATA_DIR, local_dirname, IMAGE_DIR, os.path.basename(fn)) for fn in image_files]\n",
    "    \n",
    "    \n",
    "    images = [mpimg.imread(f) for f in image_files]\n",
    "    \n",
    "    images = np.array([i[50:,][:-26] for i in images])\n",
    "    \n",
    "    return images \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def extract(dirname):\n",
    "    '''extracts training images from folders generated by the simulator\n",
    "       applies data augmentation by incorporating left/right camera angles with a correction factor'''\n",
    "    print (\"Extracting\", dirname)\n",
    "    log_fn = os.path.join(DATA_DIR, dirname, 'driving_log.csv')\n",
    "    metadata= pd.read_csv(log_fn, \n",
    "                          sep=',', \n",
    "                          names=['center', 'left', 'right', 'angle', 'throttle', 'break', 'speed'])\n",
    "    \n",
    "    #print (\"Metadata\", metadata.head())\n",
    "    \n",
    "    center_images = process_images(metadata.center, dirname)\n",
    "    left_images = process_images(metadata.left, dirname)\n",
    "    right_images = process_images(metadata.right, dirname)\n",
    "    \n",
    "    # data augmentation #1 --> use multiple camera angles\n",
    "    center_steering = np.array(metadata.angle)\n",
    "    left_steering = np.array(metadata.angle)  + CORRECTION\n",
    "    right_steering = np.array(metadata.angle) - CORRECTION\n",
    "    \n",
    "    \n",
    "    print (center_images.shape, center_steering.shape)\n",
    "    \n",
    "    Xs = np.vstack((center_images,  left_images,  right_images))\n",
    "    ys = np.hstack((center_steering, left_steering, right_steering))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size = 0.25, random_state=42)\n",
    "    \n",
    "    print (\"Final Shapes TRAIN\", X_train.shape, y_train.shape, \"TEST\", X_test.shape, y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16-Based steering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Input, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.applications import VGG16\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "\n",
    "def vgg16_steering_model(device='/gpu:1'):\n",
    "    print (\"Using Device:\",device)\n",
    "    #base_model = VGG16(include_top = False, weights='imagenet', input_shape=(84,320,3))\n",
    "    with K.tf.device(device):\n",
    "        # perform normalization at beginning of base VGG16 model\n",
    "        inp = Input(shape=(84, 320, 3))\n",
    "        norm = Lambda(lambda x: (x / 255.0) - 0.5 )(inp)\n",
    "        base_model = VGG16(include_top = False, weights=\"imagenet\", input_tensor=norm)\n",
    "\n",
    "        # disable layer training \n",
    "        for layer in base_model.layers:\n",
    "            #print (layer.name)\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Flatten incoming data to feed to FC layers\n",
    "        x = Flatten()(base_model.output)\n",
    "    \n",
    "        # add some FC layers with dropout to learn from the features detected by VGG 16\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Dense(128, activation=\"relu\")(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        prediction = Dense(1)(x)\n",
    "\n",
    "        head_model = Model(input = base_model.input, output = prediction )\n",
    "\n",
    "        opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "        head_model.compile(loss='mse', optimizer= opt)\n",
    "\n",
    "        head_model.summary()\n",
    "\n",
    "        return head_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data2', 'data1']\n",
      "Using Device: /gpu:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sven/.local/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 84, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 84, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 84, 320, 64)       1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 84, 320, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 42, 160, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 42, 160, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 42, 160, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 21, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 21, 80, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 21, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 21, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 10, 40, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 10, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 10, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 20, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 20, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 20, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 20, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               2621696   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,369,409\n",
      "Trainable params: 2,654,721\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Extracting data2\n",
      "Processing 1627 images\n",
      "Processing 1627 images\n",
      "Processing 1627 images\n",
      "(1627, 84, 320, 3) (1627,)\n",
      "Final Shapes TRAIN (3660, 84, 320, 3) (3660,) TEST (1221, 84, 320, 3) (1221,)\n",
      "Extracting data1\n",
      "Processing 1297 images\n",
      "Processing 1297 images\n",
      "Processing 1297 images\n",
      "(1297, 84, 320, 3) (1297,)\n",
      "Final Shapes TRAIN (2918, 84, 320, 3) (2918,) TEST (973, 84, 320, 3) (973,)\n",
      "Training Data Shapes\n",
      "(6578, 84, 320, 3) 2194\n",
      "Epoch 1/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 1.2468\n",
      "Epoch 2/64\n",
      "6578/6578 [==============================] - 18s 3ms/step - loss: 0.0787\n",
      "Epoch 3/64\n",
      "6578/6578 [==============================] - 18s 3ms/step - loss: 0.0423\n",
      "Epoch 4/64\n",
      "6578/6578 [==============================] - 18s 3ms/step - loss: 0.0287\n",
      "Epoch 5/64\n",
      "6578/6578 [==============================] - 18s 3ms/step - loss: 0.0228\n",
      "Epoch 6/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0178\n",
      "Epoch 7/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0146\n",
      "Epoch 8/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0125\n",
      "Epoch 9/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0108\n",
      "Epoch 10/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0097\n",
      "Epoch 11/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0089\n",
      "Epoch 12/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0078\n",
      "Epoch 13/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0073\n",
      "Epoch 14/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0068\n",
      "Epoch 15/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0059\n",
      "Epoch 16/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0054\n",
      "Epoch 17/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0051\n",
      "Epoch 18/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0049\n",
      "Epoch 19/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0046\n",
      "Epoch 20/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0043\n",
      "Epoch 21/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0041\n",
      "Epoch 22/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0039\n",
      "Epoch 23/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0038\n",
      "Epoch 24/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0035\n",
      "Epoch 25/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0036\n",
      "Epoch 26/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0034\n",
      "Epoch 27/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0031\n",
      "Epoch 28/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0031\n",
      "Epoch 29/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0033\n",
      "Epoch 30/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0029\n",
      "Epoch 31/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0030\n",
      "Epoch 32/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0027\n",
      "Epoch 33/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0027\n",
      "Epoch 34/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0031\n",
      "Epoch 35/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0026\n",
      "Epoch 36/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0024\n",
      "Epoch 37/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0024\n",
      "Epoch 38/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0023\n",
      "Epoch 39/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0023\n",
      "Epoch 40/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0024\n",
      "Epoch 41/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0023\n",
      "Epoch 42/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0022\n",
      "Epoch 43/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n",
      "Epoch 44/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 45/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0022\n",
      "Epoch 46/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0018\n",
      "Epoch 47/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n",
      "Epoch 49/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0019\n",
      "Epoch 50/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n",
      "Epoch 51/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 52/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0023\n",
      "Epoch 53/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 54/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n",
      "Epoch 55/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 56/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0021\n",
      "Epoch 57/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0025\n",
      "Epoch 58/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0024\n",
      "Epoch 59/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 60/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0020\n",
      "Epoch 61/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0018\n",
      "Epoch 62/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0023\n",
      "Epoch 63/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0027\n",
      "Epoch 64/64\n",
      "6578/6578 [==============================] - 19s 3ms/step - loss: 0.0024\n",
      "2194/2194 [==============================] - 7s 3ms/step\n",
      "Evaluation Result 0.00480686297934\n"
     ]
    }
   ],
   "source": [
    "data_dirs = os.listdir(DATA_DIR)\n",
    "\n",
    "print (data_dirs)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 64\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "\n",
    "model = vgg16_steering_model()\n",
    "\n",
    "\n",
    "def smart_append(X,Y, vstack=True):\n",
    "    if len(X) == 0:\n",
    "        return Y\n",
    "    else:\n",
    "        if vstack:\n",
    "            return np.vstack((X,Y))\n",
    "        else:\n",
    "            return np.hstack((X,Y))\n",
    "\n",
    "for d in data_dirs:\n",
    "    X_tr, X_va, y_tr, y_va = extract(d)\n",
    "    \n",
    "    X_train = smart_append(X_train, X_tr)\n",
    "    X_valid = smart_append(X_valid, X_va)\n",
    "    \n",
    "    y_train = smart_append(y_train, y_tr, vstack = False)\n",
    "    y_valid = smart_append(y_valid, y_va, vstack = False)\n",
    "\n",
    "print (\"Training Data Shapes\")\n",
    "print (X_train.shape, len(y_valid))\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE)\n",
    "\n",
    "res = model.evaluate(X_valid, y_valid)\n",
    "\n",
    "print (\"Evaluation Result\", res)\n",
    "\n",
    "import h5py\n",
    "model.save('vgg_256_128.h5')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
